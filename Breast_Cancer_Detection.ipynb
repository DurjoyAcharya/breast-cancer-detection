{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YYkBHNzDRiSptaaQUF0afqnD82Coi7hI",
      "authorship_tag": "ABX9TyOtcwD8GpPrBZwUpbVABYUL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DurjoyAcharya/breast-cancer-detection/blob/main/Breast_Cancer_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JY_0aQzpXdWJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Allocation = \"/content/drive/MyDrive/SP/UltraSoundDataset\"\n",
        "Groups = ['benign', 'malignant', 'normal']\n",
        "print(Allocation)\n",
        "print(Groups)"
      ],
      "metadata": {
        "id": "oZ9FN3wMbDu3",
        "outputId": "a843057e-bc0d-4a19-fe2b-b916e96df075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SP/UltraSoundDataset\n",
            "['benign', 'malignant', 'normal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (128, 128)"
      ],
      "metadata": {
        "id": "p1u-CRqpufrF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "CATEGORIES = sorted(list(os.listdir(Allocation)))\n",
        "for category in CATEGORIES:\n",
        "  folder = os.path.join(Allocation, category)\n",
        "  label = CATEGORIES.index(category)\n",
        "  for img in os.listdir(folder):\n",
        "    img_path = os.path.join(folder, img)\n",
        "    img_arr = cv2.imread(img_path)\n",
        "    img_arr = cv2.resize(img_arr, IMAGE_SIZE)\n",
        "    data.append([img_arr, label])\n",
        "\n",
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "b0DVneO0ug1h"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X, y = zip(*data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = [cv2.resize(img, IMAGE_SIZE) for img in X_train]\n",
        "X_test = [cv2.resize(img, IMAGE_SIZE) for img in X_test]"
      ],
      "metadata": {
        "id": "e2X160mNug_t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train, dtype=np.float32) / 255.0\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test, dtype=np.float32) / 255.0\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "kkHSVI9yuhG3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Incorporating data augmentation strategies"
      ],
      "metadata": {
        "id": "yu4Tzshj6YFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1)\n",
        "])"
      ],
      "metadata": {
        "id": "L-hk4w-Sxmm2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the model by adopting DenseNet121 and its pre-trained weights."
      ],
      "metadata": {
        "id": "bLtBqhOM67Ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(128, 128, 3), pooling = 'avg')\n",
        "\n",
        "# Freeze the layers of the pre-trained model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va2ehvHZ6_Uu",
        "outputId": "81be5eb3-3064-481d-ec82-4a46d5c4b570"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom classification head\n",
        "custom_head = tf.keras.Sequential([\n",
        "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Combine the base model and custom head\n",
        "dn = Sequential([data_augmentation, base_model, custom_head])"
      ],
      "metadata": {
        "id": "PH4g1_gi8ecr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a learning rate schedule function\n",
        "def lr_schedule(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.001\n",
        "    elif epoch < 20:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "# Create a learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ],
      "metadata": {
        "id": "8efTj00o8jN9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "\n",
        "# Use the callbacks during model training\n",
        "dn.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XpZScbD08pMO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = dn.fit(X_train, y_train, epochs=60, batch_size=128, validation_split=0.2, callbacks=[early_stopping, lr_scheduler])\n",
        "dn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LvJVOmA80_U",
        "outputId": "e7fb0e76-befd-4311-c890-bb1cf2bc67d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "8/8 [==============================] - 101s 11s/step - loss: 0.9422 - accuracy: 0.5659 - val_loss: 0.5235 - val_accuracy: 0.7984 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.6948 - accuracy: 0.6987 - val_loss: 0.4658 - val_accuracy: 0.7945 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.5357 - accuracy: 0.7611 - val_loss: 0.4135 - val_accuracy: 0.8379 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "8/8 [==============================] - 90s 12s/step - loss: 0.4541 - accuracy: 0.7948 - val_loss: 0.3879 - val_accuracy: 0.8577 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.4603 - accuracy: 0.8087 - val_loss: 0.4262 - val_accuracy: 0.7945 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "8/8 [==============================] - 107s 14s/step - loss: 0.4404 - accuracy: 0.8097 - val_loss: 0.3360 - val_accuracy: 0.8617 - lr: 0.0010\n",
            "Epoch 7/60\n",
            "8/8 [==============================] - 82s 10s/step - loss: 0.3843 - accuracy: 0.8315 - val_loss: 0.3443 - val_accuracy: 0.8775 - lr: 0.0010\n",
            "Epoch 8/60\n",
            "8/8 [==============================] - 87s 12s/step - loss: 0.3896 - accuracy: 0.8365 - val_loss: 0.3120 - val_accuracy: 0.8893 - lr: 0.0010\n",
            "Epoch 9/60\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3360 - accuracy: 0.8603 - val_loss: 0.3143 - val_accuracy: 0.8854 - lr: 0.0010\n",
            "Epoch 10/60\n",
            "8/8 [==============================] - 85s 11s/step - loss: 0.3419 - accuracy: 0.8583 - val_loss: 0.3056 - val_accuracy: 0.8854 - lr: 0.0010\n",
            "Epoch 11/60\n",
            "8/8 [==============================] - 87s 11s/step - loss: 0.3324 - accuracy: 0.8672 - val_loss: 0.3039 - val_accuracy: 0.8854 - lr: 1.0000e-04\n",
            "Epoch 12/60\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3233 - accuracy: 0.8642 - val_loss: 0.3017 - val_accuracy: 0.8893 - lr: 1.0000e-04\n",
            "Epoch 13/60\n",
            "8/8 [==============================] - 92s 12s/step - loss: 0.2997 - accuracy: 0.8791 - val_loss: 0.2979 - val_accuracy: 0.8972 - lr: 1.0000e-04\n",
            "Epoch 14/60\n",
            "8/8 [==============================] - 87s 11s/step - loss: 0.2947 - accuracy: 0.8712 - val_loss: 0.2944 - val_accuracy: 0.8933 - lr: 1.0000e-04\n",
            "Epoch 15/60\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3069 - accuracy: 0.8821 - val_loss: 0.2978 - val_accuracy: 0.8854 - lr: 1.0000e-04\n",
            "Epoch 16/60\n",
            "8/8 [==============================] - 82s 11s/step - loss: 0.3014 - accuracy: 0.8751 - val_loss: 0.2969 - val_accuracy: 0.8814 - lr: 1.0000e-04\n",
            "Epoch 17/60\n",
            "8/8 [==============================] - 84s 10s/step - loss: 0.2941 - accuracy: 0.8781 - val_loss: 0.2965 - val_accuracy: 0.8814 - lr: 1.0000e-04\n",
            "Epoch 18/60\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.2909 - accuracy: 0.8870 - val_loss: 0.2902 - val_accuracy: 0.8972 - lr: 1.0000e-04\n",
            "Epoch 19/60\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.2746 - accuracy: 0.8850 - val_loss: 0.2894 - val_accuracy: 0.8933 - lr: 1.0000e-04\n",
            "Epoch 20/60\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.2870 - accuracy: 0.8781 - val_loss: 0.2935 - val_accuracy: 0.8854 - lr: 1.0000e-04\n",
            "Epoch 21/60\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.2938 - accuracy: 0.8890 - val_loss: 0.2937 - val_accuracy: 0.8814 - lr: 1.0000e-05\n",
            "Epoch 22/60\n",
            "8/8 [==============================] - 79s 10s/step - loss: 0.2863 - accuracy: 0.8890 - val_loss: 0.2934 - val_accuracy: 0.8814 - lr: 1.0000e-05\n",
            "Epoch 23/60\n",
            "8/8 [==============================] - 83s 11s/step - loss: 0.2821 - accuracy: 0.8840 - val_loss: 0.2927 - val_accuracy: 0.8854 - lr: 1.0000e-05\n",
            "Epoch 24/60\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.2851 - accuracy: 0.8801 - val_loss: 0.2924 - val_accuracy: 0.8814 - lr: 1.0000e-05\n",
            "Epoch 25/60\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.2793 - accuracy: 0.8920 - val_loss: 0.2913 - val_accuracy: 0.8814 - lr: 1.0000e-05\n",
            "Epoch 26/60\n",
            "8/8 [==============================] - 83s 10s/step - loss: 0.2941 - accuracy: 0.8840 - val_loss: 0.2907 - val_accuracy: 0.8854 - lr: 1.0000e-05\n",
            "Epoch 27/60\n",
            "8/8 [==============================] - 87s 11s/step - loss: 0.2658 - accuracy: 0.8890 - val_loss: 0.2903 - val_accuracy: 0.8854 - lr: 1.0000e-05\n",
            "Epoch 28/60\n",
            "8/8 [==============================] - 78s 10s/step - loss: 0.2809 - accuracy: 0.8880 - val_loss: 0.2905 - val_accuracy: 0.8814 - lr: 1.0000e-05\n",
            "Epoch 29/60\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.2867 - accuracy: 0.8801 - val_loss: 0.2907 - val_accuracy: 0.8814 - lr: 1.0000e-05\n",
            "Epoch 30/60\n",
            "8/8 [==============================] - 90s 12s/step - loss: 0.2739 - accuracy: 0.8930 - val_loss: 0.2908 - val_accuracy: 0.8854 - lr: 1.0000e-05\n",
            "Epoch 31/60\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.3048 - accuracy: 0.8791 - val_loss: 0.2909 - val_accuracy: 0.8814 - lr: 1.0000e-05\n",
            "Epoch 32/60\n",
            "8/8 [==============================] - 83s 11s/step - loss: 0.2799 - accuracy: 0.8880 - val_loss: 0.2908 - val_accuracy: 0.8854 - lr: 1.0000e-05\n",
            "Epoch 33/60\n",
            "8/8 [==============================] - 84s 11s/step - loss: 0.2858 - accuracy: 0.8850 - val_loss: 0.2907 - val_accuracy: 0.8854 - lr: 1.0000e-05\n",
            "Epoch 34/60\n",
            "8/8 [==============================] - 86s 11s/step - loss: 0.2704 - accuracy: 0.8860 - val_loss: 0.2906 - val_accuracy: 0.8854 - lr: 1.0000e-05\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " densenet121 (Functional)    (None, 1024)              7037504   \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 3)                 1739011   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8776515 (33.48 MB)\n",
            "Trainable params: 1739011 (6.63 MB)\n",
            "Non-trainable params: 7037504 (26.85 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}